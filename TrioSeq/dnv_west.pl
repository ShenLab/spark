#!/usr/bin/env perl

use strict;
use warnings;
use Carp;
use IO::Dir;
use IO::File;
use Perl6::Slurp;
use Data::Dumper;
use FindBin qw|$Bin|;
use List::Util qw|min max sum|;
use List::MoreUtils qw|all any uniq|;
use Getopt::Lucid qw|:all|; 
use Config::Std;
use Hash::Util qw|lock_keys|;
use String::ShellQuote;
use Utils::Parser qw|sql_query|;
use Utils::Hash qw|chk_default merge_conf|;
use Utils::Workflow;
use Utils::File qw|count_line|;
use Utils::File::Iter qw|iter_file slurp_file|;
use Genome::UCSC qw|hg_par|;
use Genome::UCSC::GeneTable qw|iter_geneTab iter_genePred|;



use lib "$Bin/../lib";
use Variants qw|xfactor|;
use Shared qw|parse_filters parse_tabfile read_geneset read_twinsibs read_twindups parse_fstr slurp_xref expand_dat|;


my @spec =  (
	Param("conf|c")->valid(sub { -r }),
	Param("input|in|i"),
	Param("outdir|out|o"),
	Param("engine|eng")->valid(sub { $_ eq 'SGE' || $_ eq 'BASH' }),
	Keypair("param|par"),
	Switch("help|h"),
	Switch("dryrun|dry"),
	Switch("force")
	);

my $opt = Getopt::Lucid->getopt(\@spec);


if ($opt->get_help) {
	print STDERR "dnv_test.pl --conf CONFIG --out OUTDIR\n";
	print STDERR <<EOF;

Purpose: 
	This is a pipeline script implementing the DenovoWEST workflow for evaluating the significance of gene-specific
	enrichment of de novo variants.

Usage: 
	dnv_west.pl [--in DNVTable] --conf Config --out OutDir

Notes: 
	DenovoWEST is an extension of traditional Poisson test of DNV enrichment. The test statistics for each gene 
	is weighted sum of observed DNVs. Weights represent our prior brief of pathogenicity for different classes of
	DNVs. In DDD 2019, they stratified genes based on sHet >=0.15 or <0.15 and presence of absence of MCR, and 
	derived postive predictive values (PPVs) for LGD and missense variants in each gene set as a function of CADD
	score bins. They then smoothed PPVs as a function of CADD score and gene set, and use them as weights. 
	Generally, variant weights can be a function of both gene and variant specific properties. Our implementation
	allows variant weight to be a function of one or more categorical variables and one continuous variable. 
	The enrichment is evaluated by comparing observed weighted sum statistics with simulations based on per-bp 
	mutation rates. 

	To increase power for genes enriched only for missense variants, DenovoWEST also runs enrichment test using 
	only missense variants, then combines the evidence from missense clustering test by DenovoNear. The final 
	DenovoWEST p-value is the minimum of p-value for enrichment of all variants, and p-value for combined enrichment 
	and clustering of missense variants. 

	The input DNVs to DenovoWEST are assumed to be independent mutation events. To avoid inflating the test statistics 
	and creating false recurrences for DenovoNear, mutations shared by twin or sibs are counted only once. For nearby 
	variants in the same individual, only one with most severe effect should be kept.  

Input/output:
	The inputs include an annotated DNV table, a variant weight lookup table (used by utils/lookup_varwt.pl), and 
	annotations of all possible SNVs in exome (generated by enum_cdssnvs.pl). All possible SNVs in exome should be 
	enumerated from the same set of genes and annotated in the same way as input DNVs, because variant weights will
	be annotated to all variants. Per-bp mutation rates are needed for enrichment test, they will be calculated 
	from the method specified in the config.

	The workflow will first lookup variants weights and split input DNVs by gene, then prepare tables of per-bp 
	mutation rates and weights for each gene with DNVs, then run enrichment test (for all and missense variants) 
	and clustering test (for missense only) for each gene in parallel. The results of each gene will be collected 
	and reformatted in the final step. It is possible to run DenovoWEST on multiple sub-groups of the entire sample. 
	When sample groups are defined in the config, there will be one final output for each sample group.

Dependencies:
	The modified DenovoWEST scripts is included in the pipeline directory. The script depends on csvtk in part for 
	generating intermediate files. DenovoNear should be installed from source (https://github.com/jeremymcrae/denovonear).

EOF
	exit 1;

}

$opt->validate({ requires => [qw|conf outdir|] });

my %conf = merge_conf($opt->get_conf, $opt->get_param); 
$conf{PATH}{ANNODIR} = shell_quote("$Bin/../VarAnno");
$conf{PATH}{UTILDIR} = shell_quote("$Bin/utils");
$conf{PATH}{MODUDIR} = shell_quote("$Bin/module");

# If input is provided, we will use it to override the variant table specified in config
if ($opt->get_input) {
	$conf{Variant}{Table} = $opt->get_input;
	unless(-f $conf{Variant}{Table}) {
		die "Cannot find variant table: $conf{Variant}{Table}";
	}
}

lock_keys(%conf);


#############################
## Input files preparation ##
#############################

my $rootdir = $opt->get_outdir;

my $wkf = Utils::Workflow->new($rootdir,
	{ dir => 'exome', engine => $opt->get_engine, force => $opt->get_force });


# First parse sample tables to determine sample size of each group used in analysis
# This is the same as dnv_burden pipeline, male/female sample sizes should be determined 
# foreach group.

#
# Sample information
# 
my (@sampgroup, %sampgroup, %sampsize, %sampincl, %samprm, %twinsibs, %twindups);
{
	if (defined $conf{Sample}{Exclude}) {
		unless (-f $conf{Sample}{Exclude}) {
			die "Cannot find bad sample list $conf{Sample}{Exclude}";
		}
		print STDERR "Reading sample exclusion list from $conf{Sample}{Exclude}\n";
		%samprm = map { (split)[0] => 1 } slurp $conf{Sample}{Exclude};
	}
	if (defined $conf{Sample}{Include}) {
		unless (-f $conf{Sample}{Include}) {
			die "Cannot find good sample list $conf{Sample}{Include}";
		}
		print STDERR "Reading sample inclusion list from $conf{Sample}{Include}\n";
		%sampincl = map { (split)[0] => 1 } slurp $conf{Sample}{Include};
	}

	my (@samptabs, $f_iid, $f_sex);
	$f_sex = $conf{Sample}{Sex};
	if (defined $conf{Sample}{Table}) {
		if (ref $conf{Sample}{Table} eq 'ARRAY') {
			@samptabs = @{$conf{Sample}{Table}};
		}
		else {
			@samptabs = ($conf{Sample}{Table});
		}
		$f_iid = $conf{Sample}{SampID};
	}
	else {
		# Note: when gathering sample info from variant table, no variant filter will be applied
		print STDERR "Gather sample info from variant table\n";
		if (ref $conf{Variant}{Table} eq 'ARRAY') {
			@samptabs = @{$conf{Variant}{Table}};
		}
		else {
			@samptabs = ($conf{Variant}{Table});
		}
		$f_iid = $conf{Variant}{SampID};
	}
	unless(all { -f $_ } @samptabs) {
		die "Not all sample table files exist";
	}

	my $filter;
	if (exists $conf{Sample}{Filter}) {
		my $filtexpr = $conf{Sample}{Filter};
		$filtexpr =~ s/^["']//; $filtexpr =~ s/["']$//;
		($filter, my $tokens) = sql_query($filtexpr, 1);
		foreach my $samptab (@samptabs) {
			my ($it, $fnames) = iter_file($samptab, { fsep => qr/\t/ });
			foreach my $tok (@$tokens) {
				if ($tok->[0] eq 'FIELD') {
					unless(grep { $tok->[1] eq $_} @$fnames) {
						die "Cannot find Filter field $tok->[1] in sample table $samptab";
					}
				}
			}
		}
	}

	# Parse and validate sample group filters	
	my $callbacks;
	if (defined $conf{Sample}{Group}) {
		(my $samptypes, $callbacks, my $fields) = 
			parse_filters($conf{Sample}{Group}, $conf{Sample}{Group_Filter});
		foreach my $samptab (@samptabs) {
			my ($it, $fnames) = iter_file($samptab, { fsep => qr/\t/ });
			foreach my $field (keys %$fields) {
				unless(grep { $field eq $_ } @$fnames) {
					die "Cannot find field $field from sample table";
				}
			}
			unless(grep { $f_iid eq $_ } @$fnames) {
				die "Cannot find sample ID field $f_iid from sample table";
			}
			if (defined $f_sex) {
				unless(grep { $f_sex eq $_ } @$fnames) {
					die "Cannot find sample sex field $f_sex from sample table";
				}
			}
			else {
				unless($conf{Sample}{AllowNoSex} =~ /^Y/ && defined $conf{Sample}{PMale}) {
					die "Must allow no sex and provide male proportion when sample sex info is not available";
				}
			}
		}
		@sampgroup = @$samptypes;
		# Init sample sizes
		foreach my $sgroup (@sampgroup) {
			$sampsize{$sgroup}{ALL} = $sampsize{$sgroup}{M} = $sampsize{$sgroup}{F} = 0;
		}
	}
	else {
		unless(defined $conf{Sample}{Size}) {
			die "Must provide sample size when sample group is not defined";
		}
		unless($conf{Sample}{Size} =~ /^\d+$/) {
			die "Sample size for all must be a single integer!";
		}
		@sampgroup = qw|All|;
		# Set full sample size to the pre-specified 
		$sampsize{All}{ALL} = $conf{Sample}{Size};
		# Then set male/female sample sizes based on PMale
		unless($conf{Sample}{AllowNoSex} =~ /^Y/ && defined $conf{Sample}{PMale}) {
			die "Must allow no sex and provide male proportion when sample group is not defined";
		}
		unless($conf{Sample}{PMale} >= 0 && $conf{Sample}{PMale} <= 1) {
			die "Incorrect proportion of males: $conf{Sample}{PMale}";
		}
		$sampsize{All}{M} = int($sampsize{All}{ALL} * $conf{Sample}{PMale} + 0.5);
		$sampsize{All}{F} = $sampsize{All}{ALL} - $sampsize{All}{M};
	}

	# Parse sample table to get sample size for each subgroup and group memberships 
	# Should also need to check no sample overlap among different sample tables
	my ($sampct, %known, %knowntabs, %sampsex);	
	foreach my $samptab (@samptabs) {
		my ($it, $fnames) = iter_file($samptab, { fsep => qr/\t/ });
		while(my $dat = $it->()) {
			my $iid = $dat->{$f_iid};
			if (defined $filter) {
				# Sample failed sample-filter will be added to removal list
				unless ($filter->($dat)) {
					$samprm{$iid} = 1;
					next;
				}
			}
			if (%sampincl) {
				next unless defined $sampincl{$iid};
			}
			next if defined $samprm{$iid};
			if (defined $known{$iid}) {
				if (defined $conf{Sample}{Table}) {
					die "Sample $iid has already appeared in the sample table previously";
				}
				else {
					if (defined $knowntabs{$iid} && $knowntabs{$iid} ne $samptab) {
						warn "Sample $iid has appeared in some previous variant table";
					}
					next;
				}
			}
			my $sex;
			if (defined $f_sex) {
				if ($dat->{$f_sex} =~ /^M/i) {
					$sex = 'M';
					$sampsex{$iid} = 'M';
				}
				elsif ($dat->{$f_sex} =~ /^F/i) {
					$sex = 'F';
					$sampsex{$iid} = 'F';
				}
				else {
					unless($conf{Sample}{AllowNoSex} =~ /^(Y|T)/) {
						die "Cannot determine sex for $iid";
					}
					else {
						warn "Cannot determine sex for $iid: $dat->{$f_sex}";
					}
				}
			}
			if($callbacks) {
				for(my $ii = 0; $ii < @sampgroup; $ii ++) {
					if ($callbacks->[$ii]->($dat)) {
						$sampgroup{$iid}{$sampgroup[$ii]} = 1;
						$sampsize{$sampgroup[$ii]}{ALL} ++;
						$sampsize{$sampgroup[$ii]}{$sex} ++ if defined $sex;
					}
				}
			}
			$known{$iid} = 1;
			$knowntabs{$iid} = $samptab;
			$sampct ++;
		}
	}
	print STDERR "A total of $sampct samples are found in sample table.\n";

	# Now validate sample size for each group
	if (defined $conf{Sample}{Size}) {
		my $sz;
		if ($conf{Sample}{Size} =~ /^\d+$/) {
			$sz = $conf{Sample}{Size};
			if (defined $conf{Sample}{Table}) {
				unless ($sz == $sampct) {
					die "Inconsistent sample size, $sampct found in sample table <> $sz specified in config";
				}
			}
			else {
				if($sampct > $sz) {
					die "Num of samples ($sampct) found in variant table > $sz specified in config";
				}
				elsif ($sampct < $sz) {
					warn "Num of samples ($sampct) found in variant table < $sz specified in config";
					if (@sampgroup > 1) {
						warn "You need to check consistency of sample sizes for other sample groups!";
					}
				}
			}
		}
		else {
			$sz = str2hash($conf{Sample}{Size}, { psep => ',', kvsep => ':' });
			foreach my $sgroup (@sampgroup) {
				unless(defined $sz->{$sgroup}) {
					die "Cannot find sample size for group $sgroup from sample size spec from config!";
				}
				if (defined $conf{Sample}{Table}) {
					unless ($sampsize{$sgroup}{ALL} == $sz->{$sgroup}{ALL}) {
						die "Inconsistent sample size for group $sgroup, $sampsize{$sgroup}{ALL} <> $sz->{$sgroup} specified in config";
					}
				}
				else {
					if ($sampsize{$sgroup}{ALL} > $sz->{$sgroup}) {
						die "Num of samples for group $sgroup ($sampsize{$sgroup}{ALL}) found in variant table > $sz->{$sgroup} specified in config";
					}
					elsif ($sampsize{$sgroup}{ALL} < $sz->{$sgroup}) {
						warn "Num of samples for group $sgroup ($sampsize{$sgroup}{ALL}) found in variant table < $sz->{$sgroup} specified in config";
						$sampsize{$sgroup}{ALL} = $sz->{$sgroup};
						if (@sampgroup > 1) {
							warn "You need to check consistency of sample size for other sample groups!";
						}
					}
				}
			}
		}
	}

	# Read twin/sib pairs
	if (defined $conf{Sample}{Twins} || defined $conf{Sample}{Sibs}) {
		%twinsibs = read_twinsibs($conf{Sample}{Twins}, $conf{Sample}{Sibs});
	}
	# Adjusting sample sizes in the presence of MZ twins
	if (defined $conf{Sample}{Twins}) {
		%twindups = read_twindups($conf{Sample}{Twins});
		print STDERR "Adjusting sample counts for MZ twins in all groups\n";
		my %twins;
		open my $fin, $conf{Sample}{Twins} or die "Cannot open twin pairs list: $conf{Sample}{Twins}";
		while(<$fin>) {
			my @pair = split;
			unless(@pair == 2) {
				die "Incorrect line in twin pairs list: $_";
			}
			next if $twins{$pair[0],$pair[1]};
			$twins{$pair[0],$pair[1]} = 1;
			$twins{$pair[1],$pair[0]} = 1;
			# If both twins exist in the same group, minus one from the current count
			foreach my $group (@sampgroup) {
				if(defined $sampgroup{$pair[0]}{$group} && defined $sampgroup{$pair[1]}{$group}) {
					#delete $sampgroup{$pair[1]}{$group};
					$sampsize{$group}{ALL} -= 1;
					if (defined $sampsex{$pair[1]}) {
						$sampsize{$group}{$sampsex{$pair[1]}} -= 1;
					}
				}
			}
		}
	}

	# Then check if we need to adjust male/female sample sizes
	foreach my $type (@sampgroup) {
		unless ($sampsize{$type}{ALL} > 0) {
			die "No sample in group $type was found";
		}
		if ($sampsize{$type}{ALL} != $sampsize{$type}{F} + $sampsize{$type}{M}) {
			print STDERR "Imputing male/female sample sizes for $type";
			my $pm;
			my $den = $sampsize{$type}{F} + $sampsize{$type}{M};
			if ($den == 0) {
				unless($conf{Sample}{PMale}) {
					die "Cannot determine number of male/female samples for subtype $type";
				}
				unless($conf{Sample}{PMale} >= 0 && $conf{Sample}{PMale} <= 1) {
					die "Incorrect proportion of males: $conf{Sample}{PMale}";
				}
				$pm = $conf{Sample}{PMale};
			}
			else {
				$pm = $sampsize{$type}{M}/$den;
			}
			$sampsize{$type}{M} = int($sampsize{$type}{ALL}*$pm);
			$sampsize{$type}{F} = $sampsize{$type}{ALL} - $sampsize{$type}{M};
		}
	}
}

#
# Gene level info
#
# Note: if gene set is provided, each gene can only be associated with one set!
# This is different from other pipelines. The purpose of gene set is to help define
# set-specific weights for DNVs.
# If gene sets are defined, they will be written to PARDIR/GeneSet.txt
my (%geneincl, %geneexcl, %geneset);
{
	my @knownfds = qw|AllObserved AllExpected pAllEnrich MisObserved MisExpected pMisEnrich MisEvents MisDist pMisCluster pMisComb pDenovoWEST|;
	if (defined $conf{Gene}{Include}) {
		%geneincl = map { (split)[0] => 1 } slurp $conf{Gene}{Include};
	}
	if (defined $conf{Gene}{Exclude}) {
		%geneexcl = map { (split)[0] => 1 } slurp $conf{Gene}{Exclude};
	}
	if (defined $conf{Gene}{Set}) {
		my ($gs, $gsmember) = read_geneset($conf{Gene}{Set}, $conf{Gene}{Set_Fields});
		unless(defined $conf{Gene}{SetCol}) {
			die "Must provide column name for gene set!";
		}
		foreach my $gid (sort keys %$gsmember) {
			if(scalar(keys %{$gsmember->{$gid}}) > 1) {
				die "Gene $gid is associated more than one set!";
			}
		}
		if (grep { $_ eq $conf{Gene}{SetCol} } @knownfds) {
			die "Gene set field $conf{Gene}{SetCol} already exist in known gene table fields!";
		}
		open my $fout, ">$rootdir/par/GeneSet.txt" or die "Cannot write to GeneSet.txt";
		print $fout "GeneID\t", $conf{Gene}{SetCol}, "\n";
		foreach my $gid (sort keys %$gsmember) {
			my @sets = keys %{$gsmember->{$gid}};
			print $fout $gid, "\t", $sets[0], "\n";
			$geneset{$gid} = $sets[0];
		}
	}
	if (defined $conf{GeneTab}) {
		unless(defined $conf{GeneTab}{GXref} && $conf{GeneTab}{GXref_Fields}) {
			die "Cannt find gene info xref files!";
		}
		# Validate that additional gene level information fields does not conflict with standard fields.
		my (@gxrefs, @gxref_fds);
		if (ref $conf{GeneTab}{GXref_Fields}) {
			@gxref_fds = @{$conf{GeneTab}{GXref_Fields}};
			unless(ref $conf{GeneTab}{GXref} && scalar(@{$conf{GeneTab}{GXref}}) == @gxref_fds ) {
				die "Incorrect number of GXref files!";
			}
			@gxrefs = @{$conf{GeneTab}{GXref}};
		}
		else {
			@gxref_fds = ($conf{GeneTab}{GXref_Fields});
			if (ref $conf{GeneTab}{GXref}) {
				die "Incorrect number of GXref files!"
			}
			@gxrefs = ($conf{GeneTab}{GXref});
		}
		foreach my $gxref_fd (@gxref_fds) {
			my $gxfields = parse_fstr($gxref_fd, 1);
			my @gnewfields = values(%$gxfields); 
			for(my $ii = 1; $ii < @gnewfields; $ii ++) {
				if (grep { $gnewfields[$ii] eq $_ } @knownfds) {
					die "GXref field $gnewfields[$ii] already exist in known gene table fields!"
				}
			}
		}
		if (defined $conf{Gene}{SetCol}) {
			push @gxrefs, "$rootdir/par/GeneSet.txt";
			push @gxref_fds, "GeneID,$conf{Gene}{SetCol}";
		}
		my %config = (GeneTab => { GXref => \@gxrefs, GXref_Fields => \@gxref_fds });
		write_config %config, "$rootdir/par/GeneInfo.conf";
	}
	else {
		if (defined $conf{Gene}{SetCol}) {
			my %config = (GeneTab => { GXref => "$rootdir/par/GeneSet.txt", GXref_Fields => "GeneID,$conf{Gene}{SetCol}" });
			write_config %config, "$rootdir/par/GeneInfo.conf";
		}
	}
}

#
# Variant removal list
# 
# Note: varrm is not used directly but feed in as option when extract anno per gene
my (%varexcl, %varrm);
{
	if (exists $conf{Variant}{Exclude}) {
		open my $fin, $conf{Variant}{Exclude} or die "Cannot open $conf{Variant}{Exclude}";
		while(<$fin>) {
			my ($varid, $iid) = split;
			unless($varid =~ /^\w+\:\d+\:[ACGT]+\:[ACGT]+$/) {
				die "Incorrect variant ID: $varid";
			}
			if (defined $iid) {
				$varexcl{$iid,$varid} = 1;
			}
			else {
				$varexcl{$varid} = 1;
			}
		}
	}
	if (defined $conf{Variant}{Remove}) {
		open my $fin, $conf{Variant}{Remove} or die "Cannot open variant removal list: $conf{Variant}{Remove}";
		while(<$fin>) {
			my @dat = split;
			unless(@dat == 3) {
				die "Incorrect number of columns for variant removal list!";
			}
			my ($iid, $varid, $geneid) = @dat;
			unless($varid =~ /^\w+\:\d+\:[ACGT]+\:[ACGT]+$/) {
				die "Incorrect variant ID: $varid";
			}
			unless(defined $sampgroup{$iid}) {
				unless(defined $samprm{$iid}) {
					die "Cannot find sample $iid from sample table or removal list";
				}
			}
			$varrm{$iid,$varid}{$geneid} = 1;
		}
	}
}

#
# Prepare sample group specific DNV list 
#
# If twin/sib/dups present in the sample group, we will keep only one
# We will keep track of all genes in DNV table, sample groups, and their combinations
# Blacklisted genes and genes without exomeSNVs will be excluded,
my (@dnvfields, %dnvgenes);
{
	my ($qcfilter, $tokens);
	if (defined $conf{Variant}{Filter}) {
		my $filtexpr = $conf{Variant}{Filter};
		$filtexpr =~ s/^["']//; $filtexpr =~ s/["']$//;
		($qcfilter, $tokens) = sql_query($filtexpr, 1);
	}

	my @vartabs;
	if (ref $conf{Variant}{Table} eq 'ARRAY') {
		@vartabs = @{$conf{Variant}{Table}};
	}
	else {
		@vartabs = ($conf{Variant}{Table});
	}

	# Check that all fields in the filter exist in all variant tables
	my $f_iid = $conf{Variant}{SampID};
	my %opt;
	if (defined $conf{Variant}{Alias}) {
		$opt{alias} = parse_fstr($conf{Variant}{Alias}, 1);
	}
	tie my %fieldsct, "Tie::IxHash";
	foreach my $vartab (@vartabs) {
		my ($it, $fnames) = iter_file($vartab, { fsep => qr/\t/, %opt });
		foreach my $fd (@$fnames) {
			$fieldsct{$fd} ++;
		}
		my @fields = qw|Chrom Position Ref Alt GeneID|;
		push @fields => $f_iid;
		foreach my $fd (@fields) {
			unless (grep { $fd eq $_ } @$fnames) {
				die "Cannot find field $fd from input variant table";
			}
		}
		foreach my $fd (qw|prob weight|) {
			if (grep { $fd eq $_ } @$fnames) {
				die "Field $fd is reserved!";
			}
		}
		if (defined $qcfilter) {
			foreach my $tok (@$tokens) {
				if ($tok->[0] eq 'FIELD') {
					unless(grep { $tok->[1] eq $_ } @$fnames) {
						die "Cannot find QC filter field $tok->[1] in variant table $vartab";
					}
				}
			}
		}
	}

	# Go-through variant table, and prepare sample group specific DNV list
	# For twin/dup samples, ID will be standardized to the first one of dups
	# For sib pairs shared DNVs, only one will appear in the output
	# When multiple variant tables are available, we will select fields that
	# are shared in common for all tables,
	my %fouts;
	foreach my $fd (keys %fieldsct) {
		if ($fieldsct{$fd} == scalar(@vartabs)) {
			push @dnvfields, $fd;
		}
	}
	if (defined $conf{Gene}{SetCol}) {
		if (grep { $_ eq $conf{Gene}{SetCol} } @dnvfields) {
			die "Gene set column $conf{Gene}{SetCol} already exists in the DNV table!";
		}
		push @dnvfields, $conf{Gene}{SetCol};
		# We will add gene set column below
	}
	if (defined $conf{Variant}{ClassCol}) {
		if (grep { $_ eq $conf{Variant}{ClassCol} } @dnvfields) {
			die "Varian class column $conf{Variant}{ClassCol} already exists in the DNV table!";
		}
		# ClassCol will be added later by lookup_varwt.
	}

	foreach my $group (@sampgroup) {
		$fouts{$group} = IO::File->new("$rootdir/wrk/$group.txt", "w") or die "Cannot write to $group.txt";
		$fouts{$group}->print(join("\t", @dnvfields), "\n");
	}

	my %known;
	foreach my $vartab (@vartabs) {
		print STDERR "Parsing variant table $vartab\n";
		my ($it, $fnames) = iter_file($vartab, { fsep => qr/\t/, %opt });
		while(my $dat = $it->()) {
			my $iid = $dat->{$f_iid};
			if (%sampincl) {
				next unless defined $sampincl{$iid};
			}
			next if defined $samprm{$iid};

			if (defined $conf{Sample}{Table}) {
				# When sample table is provided, it is required that all samples appeared in the
				# varinat table (after removing bad samples) be listed in the sample table!
				unless(defined $sampgroup{$iid}) {
					die "Cannot find sample group for $iid in $vartab";
					#next;
				}
			}
			else {
				# If no sample table is provided, all samples found in the variant table will be added
				# to "All" group by default
				$sampgroup{$iid}{All} = 1;
			}
			
			my $varid = join(":", @{$dat}{qw|Chrom Position Ref Alt|});
			if (defined $qcfilter) {
				unless($qcfilter->($dat)) {
					$varexcl{$iid,$varid} = 1;
				}
			}
			if (%varexcl) {
				next if defined $varexcl{$iid,$varid} || defined $varexcl{$varid};
			}

			if (defined $known{$iid,$varid}) {
				#warn "Duplicated variant found in the variant table $vartab: $iid,$varid";
				next;
			}
			$known{$iid,$varid} = 1;

			my %grprm;
			# Skip DNVs shared by twin or sibs that are already observed
			if ($twinsibs{$iid}) {
				foreach my $sgroup (sort keys %{$sampgroup{$iid}}) {
					my @samegrp = grep { defined $sampgroup{$_} && defined $sampgroup{$_}{$sgroup} } @{$twinsibs{$iid}};
					if (any { defined $known{$_,$varid}  } @samegrp) {
						$grprm{$sgroup} = 1;
					}
				}
			}

			# Keep track of genes
			my @genes;
			if (%geneincl) {
				@genes = grep { $_ ne '.' && defined $geneincl{$_} && !defined $geneexcl{$_} } split(';', $dat->{GeneID});
			}
			else {
				@genes = grep { $_ ne '.' && !defined $geneexcl{$_} } split(';', $dat->{GeneID});
			}
			next unless @genes > 0;
			# Assign gene set if gene set is defined
			if (defined $conf{Gene}{SetCol}) {
				$dat->{$conf{Gene}{SetCol}} = join(";", map { $geneset{$_} // "." } split(';', $dat->{GeneID}));
			}

			# Now output group-specific DNVs after renaming twin pairs
			# They will be renamed to the primary ID of the twin/dup cluster
			foreach my $sgroup (sort keys %{$sampgroup{$iid}} ) {
				next if defined $grprm{$sgroup};
				if (defined $twindups{$iid}) {
					if (defined $known{$twindups{$iid},$varid}) {
						die "Duplicated variant $varid was not removed for twin pair $iid and $twindups{$iid}";
					}
					$dat->{$f_iid} = $twindups{$iid};
				}
				$fouts{$sgroup}->print(join("\t", @{$dat}{@dnvfields}), "\n");
				# keep record of genes-group combination 
				foreach my $gid (@genes) {
					$dnvgenes{$gid}{$sgroup} = 1;
				}
			}
		}
	}
}
my @dnvgenes = sort keys %dnvgenes;
unless(@dnvgenes > 0) {
	print STDERR "No gene was found for analysis, exit!";
	exit 1;
}

#
# Validate exome SNV directory 
#
# Confirm that exome SNVs for DNV genes can be found in the directory
foreach my $gene (@dnvgenes) {
	unless(-f "$conf{EXOMEVAR}{DIR}/$gene" || -f "$conf{EXOMEVAR}{DIR}/$gene.gz") {
		die "Cannot find exome SNV for $gene!";
	}
}
if ($conf{EXOMEVAR}{HGBUILD} =~ /^(hg19|b37)$/) {
	$conf{EXOMEVAR}{GRCBUILD} = "GRCh37";
}
elsif ($conf{EXOMEVAR}{HGBUILD} =~ /^(hg38|b38)$/) {
	$conf{EXOMEVAR}{GRCBUILD} = "GRCh38";
}
else {
	die "Cannot recognize hgbuild: $conf{EXOMEVAR}{HGBUILD}!"
}

# 
# Validate weight file
#
# Confirm that all specified fields can be found in the weight file
# and in the DNV/exomeSNV file 
{
	# If variant classes are defined, they will be written to PARDIR/VarClass.conf
	# Also update WEIGHT.CONF
	if (defined $conf{Variant}{Class}) {
		unless(defined $conf{Variant}{ClassCol}) {
			die "Must provide ClassCol for variant class";
		}
		my %config = ($conf{Variant}{ClassCol} => 
			{ Class => $conf{Variant}{Class},
			  Class_Filter => $conf{Variant}{Class_Filter} });
		write_config %config, "$rootdir/par/VarClass.conf";
		$conf{WEIGHT}{CONF} = "--conf $rootdir/par/VarClass.conf";
	}

	my ($it, $fnames) = iter_file($conf{WEIGHT}{ALLVAR}, { fsep => qr/\t/ });
	my ($it2, $fnames2) = iter_file($conf{WEIGHT}{MISSENSE}, { fsep => qr/\t/ });
	# We also randomly select the first exome SNV file
	my @exomefields;
	if (-f "$conf{EXOMEVAR}{DIR}/$dnvgenes[0]") {
		my ($it3, $fnames3) = iter_file("$conf{EXOMEVAR}{DIR}/$dnvgenes[0]", { fsep => qr/\t/ });
		@exomefields = @$fnames3;
	}
	elsif (-f "$conf{EXOMEVAR}{DIR}/$dnvgenes[0].gz") {
		my ($it3, $fnames3) = iter_file("$conf{EXOMEVAR}{DIR}/$dnvgenes[0].gz", { fsep => qr/\t/ });
		@exomefields = @$fnames3;
	}
	else {
		die "Cannot find exome SNV for $dnvgenes[0]!";
	}
	foreach my $fd (qw|prob weight|) {
		if (grep { $fd eq $_ } @exomefields) {
			die "Field $fd is reserved!";
		}
	}
	if (defined $conf{Gene}{SetCol}) {
		push @exomefields, $conf{Gene}{SetCol};
	}

	unless($conf{WEIGHT}{FIELDS} =~ /[\,\:]weight$/) {
		die "Must rename the final weight field to weight!"
	}
	my $wtfields = parse_fstr($conf{WEIGHT}{FIELDS}, 1);
	my @fillin;
	unless(defined $wtfields->{$conf{WEIGHT}{SCORE}}) {
		die "Cannot find score field $conf{WEIGHT}{SCORE} in specified field list!";
	}
	my $flag;
	foreach my $wtfd (keys %$wtfields) {
		unless(grep { $_ eq $wtfd } @$fnames) {
			die "Cannot find weight field $wtfd from all-variants weight table!";
		}
		unless(grep { $_ eq $wtfd } @$fnames2) {
			die "Cannot find weight field $wtfd from missense-variants weight table!";
		}
		my $infd = $wtfields->{$wtfd};
		unless($flag) {
			unless( (grep { $_ eq $infd } @dnvfields) || defined $conf{Variant}{ClassCol} && $infd eq $conf{Variant}{ClassCol} )  {
				die "Cannot find field $infd from DNV table!";
			}
			unless( (grep { $_ eq $infd } @exomefields) || defined $conf{Variant}{ClassCol} && $infd eq $conf{Variant}{ClassCol} ) {
				die "Cannot find field $infd from exome SNV table!";
			}
			$flag = 1 if $wtfd eq $conf{WEIGHT}{SCORE};
			push @fillin, $infd unless $flag;
		}
	}
	unless(@fillin >= 1) {
		die "Cannot find matching categorical fields for determining weight!";
	}
	$conf{EXOMEVAR}{FILLINS} = join(',', @fillin);
}

# 
# Prepare other input files for the workflow
#
# Write sample groups list to PARDIR/groups._INDEX_
for(my $ii = 0; $ii < @sampgroup; $ii ++) {
	my $jj = $ii + 1;
	my $group = $sampgroup[$ii];
	open my $fout, ">$rootdir/par/groups.$jj" or die "Cannot write to groups.$jj";
	print $fout join("\t", $group, $sampsize{$group}{M}, $sampsize{$group}{F}), "\n";
}

# Write genes with DNVs list to PARDIR/genes._INDEX_
for(my $ii = 0; $ii < @dnvgenes; $ii ++) {
	my $jj = $ii + 1;
	my $gene = $dnvgenes[$ii];
	open my $fout, ">$rootdir/par/genes.$jj" or die "Cannot write to genes.$jj";
	print $fout $gene, "\n";
}

# Write genes, sample group combination to PARDIR/genes_bygrp._INDEX_
my $count = 1;
foreach my $gene (@dnvgenes) {
	foreach my $group (sort keys %{$dnvgenes{$gene}}) {
		open my $fout, ">$rootdir/par/genes_bygrp.$count" or die "Cannot write to genes_bygrp.$count";
		print $fout join("\t", $gene, $group, $sampsize{$group}{M}, $sampsize{$group}{F}), "\n";
		$count ++;
	}
}



#################################
##  Workflow initialization &  ##
##  Working directory setup    ##
#################################


$wkf->add(lookup_dnvwt(), { name => "DNVweight", nslots => scalar(@sampgroup),
							expect => [ map { "wrk/${_}_wweight.txt" } @sampgroup ],
							callback => \&check_weights })
	->add(dnv_pergene(), { name => "DNVperGene", depend => "DNVweight",
						   nslots => scalar(@sampgroup),  expect => [dnv_pergene_exp("wweight.txt")]  })
	->add(exome_snvs(), { name => "ExomeSNVs", nslots => scalar(@dnvgenes),
						  expect => [ map { "exome/$_" } @dnvgenes ] })
	->add(lookup_exomeprob(), { name => "ExomeProb", depend => "ExomeSNVs",
								nslots => scalar(@dnvgenes),
								expect => [ map { "exome/${_}_wprob.txt" } @dnvgenes ] })
	->add(lookup_exomewt(), { name => "ExomeWeight", depend => "ExomeProb",
							 	nslots =>  scalar(@dnvgenes), 
							 	expect => [ map { "exome/${_}_wweight.txt" } @dnvgenes ] })
	->add(dne_test(), { name => "DNETest", depend => [qw|DNVperGene ExomeWeight|], 
						nslots => sum(map { scalar(keys %{$dnvgenes{$_}}) } @dnvgenes), 
						expect => [ dn_test_exp("allenrich.txt", "allenrich.log") ],
						callback => \&check_nonempty });
if(defined $conf{WEIGHT}{MISSENSE}) {
	$wkf->add(lookup_dnvwt_mis(), { name => "misDNVweight", nslots => scalar(@sampgroup),
								expect => [ map { "wrk/${_}_wmisweight.txt" } @sampgroup ],
								callback => \&check_weights })
		->add(dnv_pergene("missense"), { name => "misDNVperGene", depend => "misDNVweight",
									   	 nslots => scalar(@sampgroup),  expect => [dnv_pergene_exp("wmisweight.txt")] })
		->add(lookup_exomewt_mis(), { name => "misExomeWeight", depend => "ExomeProb",
							  	  	  nslots =>  scalar(@dnvgenes), 
									  expect => [ map { "exome/${_}_wmisweight.txt" } @dnvgenes ] })
		->add(dne_test("missense"), { name => "misDNETest", depend => [qw|misDNVperGene misExomeWeight|], 
							nslots => sum(map { scalar(keys %{$dnvgenes{$_}}) } @dnvgenes), 
							expect => [ dn_test_exp("misenrich.txt", "misenrich.log") ],
							callback => \&check_nonempty })
		->add(denovo_near(), { name => "ClstTest", depend => "misDNVperGene",
							   nslots => sum(map { scalar(keys %{$dnvgenes{$_}}) } @dnvgenes), 
							   expect => [ dn_test_exp("dnclstin.txt", "dncluster.txt") ] })
		->add(collect_res(), { name => "CollectRes", depend => [qw|DNETest misDNETest|],
								expect => [ map { "out/DenovoWEST_$_.txt" } @sampgroup ] });
}
else {
	$wkf->add(collect_res(), { name => "CollectRes", depend => "DNETest", 
								expect => [ map { "out/DenovoWEST_$_.txt" } @sampgroup ] });
}

$wkf->inst(\%conf);
$wkf->run({ conf => $conf{$wkf->{engine}}, dryrun => $opt->get_dryrun });


############################
## Workflow components    ##
############################

# DNVs for different sample groups should have been written to _WRKDIR_/SampGroup.txt
# If gene set is customized, it should also have been added to those intermediate files.
# Those tables should only include columns necessary for determining weights and rates
# First lookup variant weights for input DNVs
sub lookup_dnvwt {
	my $script = << 'EOF';

read GROUP NMale NFemale < _PARDIR_/groups._INDEX_

perl _PATH.ANNODIR_/utils/lookup_varwt.pl --in _WRKDIR_/$GROUP.txt \
	--weight _WEIGHT.ALLVAR_ --weight-fields _WEIGHT.FIELDS_ --score _WEIGHT.SCORE_ \
	_WEIGHT.CONF_ --output _WRKDIR_/${GROUP}_wweight.txt

EOF
}

# Separate out the missense variants
sub lookup_dnvwt_mis {
	my $script = << 'EOF';

read GROUP NMale NFemale < _PARDIR_/groups._INDEX_

perl _PATH.ANNODIR_/utils/lookup_varwt.pl --in _WRKDIR_/$GROUP.txt \
	--weight _WEIGHT.MISSENSE_ --weight-fields _WEIGHT.FIELDS_ --score _WEIGHT.SCORE_ \
	_WEIGHT.CONF_ --output _WRKDIR_/${GROUP}_wmisweight.txt

EOF
	return $script;
}

sub check_weights {
	my (@exp) = @_;
	#"wrk/${_}_wweight.txt"
	if (all { -f "$rootdir/$_" } @exp) {
		foreach my $wtfile (@exp) {
			my $rawfile = $wtfile; $rawfile =~ s/_(wweight|wmisweight)\.txt$/.txt/;
			my $rawlinect = count_line("$rootdir/$rawfile");
			my $wtlinect = count_line("$rootdir/$wtfile");
			if ($rawlinect == $wtlinect) {
				return 1;
			}
			else {
				return 0;
			}
		}
	}
	else {
		return 0;
	}
}

# For group-specific DNVs need to extract one table for each gene
# Should remove columns that may cause ambiguity in spliting
sub dnv_pergene {
	my ($missense) = @_;
	my $script = <<'EOF';

read GROUP NMale NFemale < _PARDIR_/groups._INDEX_

csvtk sort -t -k Chrom:N -k Position:n _WRKDIR_/${GROUP}_wweight.txt | \
	perl _PATH.ANNODIR_/module/extract_anno_pergene.pl --prefix - \
		COLOPTION VARREMOVE --suffix wweight.txt --outdir _WRKDIR_/$GROUP

EOF
	if (defined $conf{Variant}{ColRemove}) {
		if (defined $conf{Variant}{ColKeep}) {
			warn "Can only provide either ColKeep or CokRemove!";
		}
		$script =~ s/COLOPTION/--col-remove $conf{Variant}{ColRemove}/g;
	}
	elsif (defined $conf{Variant}{ColKeep}) {
		$script =~ s/COLOPTION/--col-keep $conf{Variant}{ColKeep}/g;
	}
	else {
		$script =~ s/COLOPTION//;
	}
	if (defined $conf{Variant}{Remove}) {
		$script =~ s/VARREMOVE/--varrm $conf{Variant}{Remove}/g;
	}
	else {
		$script =~ s/VARREMOVE//;
	}
	if ($missense) {
		$script =~ s/wweight/wmisweight/g;
	}
	return $script;
}


sub dnv_pergene_exp {
	my ($suffix) = @_;
	my @exp;
	foreach my $group (@sampgroup) {
		my @genes = grep { defined $dnvgenes{$_}{$group} } @dnvgenes;
		push @exp, [map { "wrk/$group/${_}.$suffix" } @genes];
	}
	return @exp;
}


# Prepare exome SNV files
# When gene set is defined, we need to adding gene set info to exome SNVs, otherwise just copy or unzip
# for genes that have DNVs from input
sub exome_snvs {
	my $script;
	if (defined $conf{Gene}{Set}) {
		$script = << 'EOF';

read GENEID < _PARDIR_/genes._INDEX_

if [[ -f _EXOMEVAR.DIR_/$GENEID ]]; then
	AFILE=_EXOMEVAR.DIR_/$GENEID
elif [[ -f _EXOMEVAR.DIR_/$GENEID.gz ]]; then
	AFILE=_EXOMEVAR.DIR_/$GENEID.gz
else
	echo "Cannot find ExomeSNV file for $GENEID!" 2>&1
fi

table_intersect.pl -a $AFILE -a-fsep "\t" -b _PARDIR_/GeneSet.txt -b-fsep "\t" OPTIONS -out _EXOMEDIR_/$GENEID

EOF
		if (defined $conf{EXOMEVAR}{ALIAS}) {
			$script =~ s/OPTIONS/-a-alias $conf{EXOMEVAR}{ALIAS}/;
		}
		else {
			$script =~ s/OPTIONS//;
		}
	}
	else {
		$script = << 'EOF';

read GENEID < _PARDIR_/genes._INDEX_

if [[ -f _EXOMEVAR.DIR_/$GENEID ]]; then
	cat _EXOMEVAR.DIR_/$GENEID OPTIONS >  _EXOMEDIR_/$GENEID
elif [[ -f _EXOMEVAR.DIR_/$GENEID.gz ]]; then
	zcat _EXOMEVAR.DIR_/$GENEID.gz OPTIONS > _EXOMEDIR_/$GENEID
else
	echo "Cannot find ExomeSNV file for $GENEID!" 2>&1
fi

EOF
		if (defined $conf{EXOMEVAR}{ALIAS}) {
			my $alias = parse_fstr($conf{EXOMEVAR}{ALIAS}, 1);
			my $oldnames = join(',', keys %$alias);
			my $newnames = join(',', values %$alias);
			$script =~ s/OPTIONS/ | csvtk rename -t -f $oldnames -n $newnames/;
		}
		else {
			$script =~ s/OPTIONS//;
		}
	}
	return $script;
}

# The whole-exome possible SNVs should have been added to exome directory
# First, lookup mutation rates
sub lookup_exomeprob {
	my $script = << 'EOF';

read GENEID < _PARDIR_/genes._INDEX_

perl _PATH.ANNODIR_/utils/lookup_bprate.pl --in _EXOMEDIR_/${GENEID} \
	OPTIONS --field-add prob --output _TMPDIR_/${GENEID}_wprob.txt

perl _PATH.MODUDIR_/fix_dnwest_indelrate.pl --in _TMPDIR_/${GENEID}_wprob.txt --fix _EXOMEVAR.CUSTOM_ \
	--fill _EXOMEVAR.FILLINS_  --out _EXOMEDIR_/${GENEID}_wprob.txt

EOF
	my @args = grep { defined $conf{MutRate}{$_} } qw|Method Lookup Fasta Rate Weight Scale Chunk|;
	my $options = join(" ", map { my $opt = lc($_); "--$opt $conf{MutRate}{$_}"  } @args);
	$script =~ s/OPTIONS/$options/;
	return $script;
}

# then lookup weights 
sub lookup_exomewt {
	my $script = << 'EOF';

read GENEID < _PARDIR_/genes._INDEX_

perl _PATH.ANNODIR_/utils/lookup_varwt.pl --in _EXOMEDIR_/${GENEID}_wprob.txt \
	--weight _WEIGHT.ALLVAR_ --weight-fields _WEIGHT.FIELDS_ --score _WEIGHT.SCORE_ \
	_WEIGHT.CONF_ --output _EXOMEDIR_/${GENEID}_wweight.txt

EOF
	return $script;
}

sub lookup_exomewt_mis {
	my $script = << 'EOF';

read GENEID < _PARDIR_/genes._INDEX_

perl _PATH.ANNODIR_/utils/lookup_varwt.pl --in _EXOMEDIR_/${GENEID}_wprob.txt \
	--weight _WEIGHT.MISSENSE_ --weight-fields _WEIGHT.FIELDS_ --score _WEIGHT.SCORE_ \
	_WEIGHT.CONF_ --output _EXOMEDIR_/${GENEID}_wmisweight.txt

EOF
	return $script;
}

# Reformat the rate table to scale the rate for each group to be tested
# Then perform test for each sample group and each gene
sub dne_test {
	my ($missense) = @_;
	my $script;
	if (exists $conf{CONDA}) {
		$script = <<'EOF';
source _CONDA.INIT_
conda activate _CONDA.ENV_

EOF
		
	}
	$script .= << 'EOF';

read GENEID GROUP NMale NFemale < _PARDIR_/genes_bygrp._INDEX_

if [[ -f _WRKDIR_/$GROUP/${GENEID}_allenrich.log ]]; then
	rm -f _WRKDIR_/$GROUP/${GENEID}_allenrich.txt
fi 


python _PATH.UTILDIR_/DNE_test.py --denovos _WRKDIR_/$GROUP/${GENEID}.wweight.txt --rates _EXOMEDIR_/${GENEID}_wweight.txt \
	--nmales $NMale --nfemale $NFemale --hgbuild _EXOMEVAR.HGBUILD_ --out _WRKDIR_/$GROUP/${GENEID}_allenrich.txt

EOF
	if ($missense) {
		$script =~ s/allenrich/misenrich/g;
		$script =~ s/wweight/wmisweight/g;
	}
	return $script;
}


# Run de novo near for testing clustering of missense variants.
# Should prepare input for de novo near
sub denovo_near {
	my $script;
	if (exists $conf{CONDA}) {
		$script = <<'EOF';
source _CONDA.INIT_
conda activate _CONDA.ENV_

EOF
	}
	$script .= <<'EOF';

read GENEID GROUP NMale NFemale < _PARDIR_/genes_bygrp._INDEX_

perl _PATH.MODUDIR_/prep_dnnear_input.pl _WRKDIR_/$GROUP/${GENEID}.wmisweight.txt _WRKDIR_/$GROUP/${GENEID}_dnclstin.txt 

denovonear cluster --genome-build _EXOMEVAR.GRCBUILD_ --in _WRKDIR_/$GROUP/${GENEID}_dnclstin.txt --out _WRKDIR_/$GROUP/${GENEID}_dncluster.txt

EOF
	return $script;
}


sub dn_test_exp {
	my @suffix = @_;
	my @exp;
	foreach my $gid (@dnvgenes) {
		foreach my $group (sort keys %{$dnvgenes{$gid}}) {
			push @exp, [map { "wrk/$group/${gid}_$_" } @suffix];
		}
	}
	return @exp;
}

# Collect denovoWEST results
sub collect_res {
	my $script = <<'EOF';

perl _PATH.MODUDIR_/collect_denovowest.pl _PARDIR_ _WRKDIR_ _OUTDIR_

EOF
}

# Check that DenovoWEST output are not empty
sub check_nonempty {
	my @exp = @_;
	if (all { -s "$rootdir/$_" } @exp) {
		return 1;
	} else {
		return 0;
	}
}


