#!/usr/bin/env perl

use strict;
use warnings;
use Carp;
use IO::Dir;
use IO::File;
use Perl6::Slurp;
use Data::Dumper;
use FindBin qw|$Bin|;
use List::Util qw|min max|;
use List::MoreUtils qw|all any uniq none|;
use Getopt::Lucid qw|:all|; 
use Config::Std;
use Hash::Util qw|lock_keys|;
use String::ShellQuote;
use FaSlice;
use Utils::List qw|all_combs|;
use Utils::Hash qw|chk_default merge_conf|;
use Utils::Workflow;
use Utils::File::Iter qw|iter_file slurp_file|;
use Genome::UCSC qw|hg_par|;
use Genome::UCSC::TwoBit;
use Genome::UCSC::GeneTable qw|iter_geneTab iter_genePred|;


use lib "$Bin/../lib";
use Variants qw|xfactor|;
use Shared qw|parse_filters parse_tabfile read_geneset parse_fstr read_twinsibs expand_dat|;

#############################
## Command line interface  ##
#############################

my @spec =  (
	Param("conf|c")->valid(sub { -r }),
	Param("input|in"),
	Param("outdir|out"),
	Param("engine|eng")->valid(sub { $_ eq 'SGE' || $_ eq 'BASH' }),
	Keypair("param|par"),
	Switch("help|h"),
	Switch("dryrun|dry"),
	Switch("force")
	);

my $opt = Getopt::Lucid->getopt(\@spec);

if ($opt->get_help) {
	print STDERR "dnv_enrich.pl --conf CONFIG -out OUTPUT_PREFIX\n";
	print STDERR <<EOF;
Purpose: 
	This is a pipeline script that evaluates gene set enrichment of DNVs in different gene sets and sample groups
	using dnenrich algorithm.

Usage:
	dnv_enrich.pl [--in VarTable] --conf Conf --out OutDir

Notes:
	Gene set enrichment of DNVs is different DNV burden. It tests if a gene set was hit by a group of DNVs more
	often than expected given the genome-wide burden of DNVs. To begin the enrichment analysis, we first define variant
	classes, take one or more classes as a group and optinally associate different classes with different weights. 
	The "hit statistics" of a gene set is defined by the summation of weights of variants in the group that are mapped 
	to the genes in the set. dnenrich then uses a permutation approach to randomly simulate the same number of variants
	onto the callable region of background genes in a way that matches the tri-nucleotide sequence context and functional 
	effects of observed variants in the group. Comparing observed with expected hit statistics from simulation gives 
	fold enrichment for a gene set and associated p-value.

	dnenrich can also contrast the enrichment between sample groups for a gene set. The test statistics is the hit stat
	of Group 1 divided by the sum of hit stat of two groups ("relative hit proportion"). It does the simulation separately
	for different groups of samples that matches the properties of mutations. Fold enrichment and signfiance are evaluated
	by comparing the observed with expected relative hit proportion.

	In each analysis, dnenrich also tests the signficance of "recurrence" by restricting the calculation of test statistics
	using mutations that mapped to genes with multiple hits. 

	The input DNVs to dnenrich are assumed to be independent mutation events. To avoid inflating the test statistics and
	creating false recurrences, mutations shared by twin or sibs are counted only once. For nearby variants in the same
	individual, only one with most severe effect should be kept.  

	The methods is described in the following pubication:
	Purcell S et al. (2014). A polygenic burden of rare disruptive mutations in schizophrenia. Nature 506:185-90.

Dependency:
	Executable dnenrich (https://bitbucket.org/statgen/dnenrich/src) should be compiled from source and added to PATH.

Input/Output:
	The input files are similar to dnv_burden.pl, except that the per-gene mutation rate table should be replaced by
	a gene size matrix (generated by gene_sizemat.pl). It also looks for the definitions of variant classes, sample groups
	and gene sets from the config. The config file will further define variant groups from classes and weights for
	different classes. 

	dnenrich will run in parallel for different combinations of variant class, sample group or group pairs, and 
	background gene sets. Then results will be collected into following two final output files in out directory:
	 	* Enrich.txt -- Enrichment of variants hits in gene sets by different variant and sample groups.
	 	* Contra.txt -- Contrast of variant hits between sample groups in gene sets by different variant groups. 
 	
EOF
	exit 1;
}

$opt->validate({ requires => [qw|conf outdir|] });

my %conf = merge_conf($opt->get_conf, $opt->get_param); 

# If input is provided, we will over-ride the VarTab in config
if ($opt->get_input) {
	$conf{Variant}{Table} = $opt->get_input;
	unless(-f $conf{Variant}{Table}) {
		die "Cannot find variant table: $conf{Variant}{Table}";
	}
}


#############################
## Input files preparation ##
#############################

my $rootdir = $opt->get_outdir;

my $wkf = Utils::Workflow->new($rootdir,
	{ engine => $opt->get_engine, force => $opt->get_force });

#
# Sample Information
# 
# In this pipeline, we do not make explicit use of full-sample level information and full sample sizes, 
# only group membership of samples who carry variants will be used.
my (%sampgroup, %sampincl, %samprm, %twinsibs, @analysgroup);
{
	# Inclusion/exclusion list
	if (defined $conf{Sample}{Exclude}) {
		unless (-f $conf{Sample}{Exclude}) {
			die "Cannot find bad sample list $conf{Sample}{Exclude}";
		}
		print STDERR "Reading sample exclusion list from $conf{Sample}{Exclude}\n";
		%samprm = map { (split)[0] => 1 } slurp $conf{Sample}{Exclude};
	}
	if (defined $conf{Sample}{Include}) {
		unless (-f $conf{Sample}{Include}) {
			die "Cannot find good sample list $conf{Sample}{Include}";
		}
		print STDERR "Reading sample inclusion list from $conf{Sample}{Include}\n";
		%sampincl = map { (split)[0] => 1 } slurp $conf{Sample}{Include};
	}
	# Twin/sib pairs
	if (defined $conf{Sample}{Twins} || defined $conf{Sample}{Sibs}) {
		%twinsibs = read_twinsibs($conf{Sample}{Twins}, $conf{Sample}{Sibs});
	}

	# Sample table and ID field
	my (@samptabs, $f_iid);
	if (defined $conf{Sample}{Table}) {
		if (ref $conf{Sample}{Table} eq 'ARRAY') {
			@samptabs = @{$conf{Sample}{Table}};
		}
		else {
			@samptabs = ($conf{Sample}{Table});
		}
		$f_iid = $conf{Sample}{SampID};
	}
	else {
		print STDERR "Gather sample info from variant table\n";
		if (ref $conf{Variant}{Table} eq 'ARRAY') {
			@samptabs = @{$conf{Variant}{Table}};
		}
		else {
			@samptabs = ($conf{Variant}{Table});
		}
		$f_iid = $conf{Variant}{SampID};
	}
	unless(all { -f $_ } @samptabs) {
		die "Not all sample table files exist";
	}

	my $filter;
	if (exists $conf{Sample}{Filter}) {
		my $filtexpr = $conf{Sample}{Filter};
		$filtexpr =~ s/^["']//; $filtexpr =~ s/["']$//;
		($filter, my $tokens) = sql_query($filtexpr, 1);
		foreach my $samptab (@samptabs) {
			my ($it, $fnames) = iter_file($samptab, { fsep => qr/\t/ });
			foreach my $tok (@$tokens) {
				if ($tok->[0] eq 'FIELD') {
					unless(grep { $tok->[1] eq $_} @$fnames) {
						die "Cannot find Filter field $tok->[1] in sample table $samptab";
					}
				}
			}
		}
	}
	
	# Parse sample tables
	# Note: we do not tally sample size each group in this pipeline
	# because dnenrich test the enrichment conditional on the observed variants.
	# We only keep track of sample group membership.
	# Different from dnv_burden, sample group must be defined!
	my ($samptypes, $callbacks, $fields) = 
		parse_filters($conf{Sample}{Group}, $conf{Sample}{Group_Filter});
	my @sampgroup = @$samptypes;
	
	my %known;
	foreach my $samptab (@samptabs) {
		my ($it, $fnames) = iter_file($samptab, { fsep => qr/\t/ });
		foreach my $field (keys %$fields) {
			unless(grep { $field eq $_ } @$fnames) {
				die "Cannot find field $field from sample table";
			}
		}
		unless(grep { $f_iid eq $_ } @$fnames) {
			die "Cannot find sample ID field $f_iid from sample table";
		}
		while(my $dat = $it->()) {
			my $iid = $dat->{$f_iid};
			if (defined $filter) {
				# Sample failed sample-filter will be added to removal list
				unless ($filter->($dat)) {
					$samprm{$iid} = 1;
					next;
				}
			}
			if (%sampincl) {
				next unless defined $sampincl{$iid};
			}
			next if defined $samprm{$iid};
			if (defined $known{$iid}) {
				if (defined $conf{Sample}{Table}) {
					die "Sample $iid has appeard in the sample table previously";
				}
				else {
					next;
				}
			}
			for(my $ii = 0; $ii < @sampgroup; $ii ++) {
				if ($callbacks->[$ii]->($dat)) {
					$sampgroup{$iid}{$sampgroup[$ii]} = 1;
				}
			}
			$known{$iid} = 1;
		}
	}

	# Analysis groups (for testing enrichment) or group pairs (for making comparisons)
	foreach my $gpair (map { [ split(':') ] } split(',', $conf{Sample}{Analysis})) {
		if (@$gpair == 1) {
			unless(grep { $gpair->[0] eq $_ } @sampgroup) {
				die "Cannot find $gpair->[0] from defined sample groups";
			}
			push @analysgroup, $gpair;
		}
		elsif (@$gpair == 2) {
			unless((grep { $gpair->[0] eq $_ } @sampgroup) && 
				   (grep { $gpair->[1] eq $_ } @sampgroup)) {
				die  "Cannot find @{[ join(q|,|, @$gpair) ]} from sample groups";
			}
			push @analysgroup, $gpair;
		}
		else {
			die "Incorrect number of groups for analysis!";
		}
	}
}

my %varrm;
if (defined $conf{Variant}{Remove}) {
	open my $fin, $conf{Variant}{Remove} or die "Cannot open variant exclusion list";
	while(<$fin>) {
		my @dat = split;
		unless(@dat == 3) {
			die "Incorrect number of columns for variant removal list!";
		}
		my ($iid, $varid, $geneid) = @dat;
		unless($varid =~ /^\w+\:\d+\:[ACGT]+\:[ACGT]+$/) {
			die "Incorrect variant ID: $varid";
		}
		unless(defined $sampgroup{$iid}) {
			unless(defined $samprm{$iid}) {
				die "Cannot find sample $iid from sample table or removal list";
			}
		}
		$varrm{$iid,$varid}{$geneid} = 1;
	}
}

# Slurp varaint exclusion list (this is different from variant removal list!)
my %varexcl;
if (exists $conf{Variant}{Exclude}) {
	open my $fin, $conf{Variant}{Exclude} or die "Cannot open $conf{Variant}{Exclude}";
	while(<$fin>) {
		my ($varid, $iid) = split;
		if (defined $iid) {
			$varexcl{$iid,$varid} = 1;
		}
		else {
			$varexcl{$varid} = 1;
		}
	}
}

my $seq;
if (defined $conf{Variant}{Fasta}) {
	if ($conf{Variant}{Fasta} =~ /\.2bit$/) {
		$seq = Genome::UCSC::TwoBit->new($conf{Variant}{Fasta});
	}
	else {
		$seq = FaSlice->new(file => $conf{Variant}{Fasta});
	}
}

#
# Variant Classes
#
# Also parse variant tables to prepare input files, currently we only consider 3mer context
my ($varcls, $filters, $fields, @analysclass, %clsalias);
# @analysclass: Each element will be  array ref: class name, {Class=>Weight} hash
# %clsalias: alias to each variant class that appear in the gene size matrix
{
	($varcls, $filters, $fields) = parse_filters($conf{Variant}{Class}, $conf{Variant}{Class_Filter});
	my (@combs, @combdefs, %combclass);
	if (defined $conf{Variant}{Comb}) {
		if (ref $conf{Variant}{Comb} eq 'ARRAY') {
			@combs = @{$conf{Variant}{Comb}};
			unless( defined $conf{Variant}{Comb_Define} &&
				ref $conf{Variant}{Comb_Define} eq 'ARRAY' &&
				scalar(@{$conf{Variant}{Comb_Define}}) == @combs ) {
				die "Incorrect number of comb field definitions";
			}
			@combdefs = @{$conf{Variant}{Comb_Define}};
		}
		else {
			@combs = ($conf{Variant}{Comb});
			unless (defined $conf{Variant}{Comb_Define} ) {
				die "Cannot find definition for comb field";
			}
			else {
				if (ref $conf{Variant}{Comb_Define} eq 'ARRAY') {
					die "Incorrect number of comb field definition";
				}
			}
			@combdefs = ($conf{Variant}{Comb_Define});
		}
	}
	for(my $ii = 0; $ii < @combs; $ii ++) {
		if (defined $combclass{$combs[$ii]} || (grep { $_ eq $combs[$ii] } @$varcls)) {
			die "Combination class $_ was already defined";
		}
		my %clswt;
		my @terms = split('\+', $combdefs[$ii]);
		foreach my $term (@terms) {
			my @spterm = split('\*', $term);
			if (@spterm == 1) {
				$clswt{$spterm[0]} = 1;
				unless (grep { $_ eq $spterm[0] } @$varcls) {
					die "Cannot find term $spterm[1] from defined variant class";
				}
			}
			elsif (@spterm == 2) {
				unless($spterm[0] =~ /^[0-9\.]+$/) {
					print Dumper \@spterm;
					die "Incorrect format of combination term: $term";
				}
				$clswt{$spterm[1]} = $spterm[0];
				unless (grep { $_ eq $spterm[1] } @$varcls) {
					die "Cannot find term $spterm[1] from defined variant class";
				}
			}
			else {
				die "Cannot split fields to find coefficient and term";
			}		
		}
		$combclass{$combs[$ii]} = \%clswt;
	}
	# Analysis class
	foreach my $class (split(',', $conf{Variant}{Analysis})) {
		if (grep { $_ eq $class } @$varcls) {
			push @analysclass, [$class, { $class => 1 }];
		}
		elsif (defined $combclass{$class}) {
			push @analysclass, [$class, $combclass{$class}];
		}
		else {
			die "Cannot find the definition of analysis class $class";
		}
	}
	# ... and class alias
	%clsalias = parse_fstr($conf{GeneSize}{VarClass});
	unless(all { defined $clsalias{$_} } map { keys %{$_->[1]} } @analysclass) {
		#print Dumper \@analysclass, \%clsalias;
		die "Not all analysis class can be found in gene size matrix!";
	}
}


# Preapre mutation lists
# wrk/varlist_VarClass_SampGroup or wrk/varlist_VarClass_Group1vsGroup2
my @outfiles;
{
	# QC filter and variant exclusion list
	my ($qcfilter, $tokens);
	if (exists $conf{Variant}{Filter}) {
		my $filtexpr = $conf{Variant}{Filter};
		$filtexpr =~ s/^["']//; $filtexpr =~ s/["']$//;
		($qcfilter, $tokens) = sql_query($filtexpr, 1);
	}

	# Parse variant tables
	my @vartabs;
	if (ref $conf{Variant}{Table} eq 'ARRAY') {
		@vartabs = @{$conf{Variant}{Table}};
	}
	else {
		@vartabs = ($conf{Variant}{Table});
	}
	# Check all fields in the filter exist in all variant tables
	my $f_iid = $conf{Variant}{SampID};
	foreach my $vartab (@vartabs) {
		my ($it, $fnames) = iter_file($vartab, { fsep => qr/\t/ });
		my @fields = qw|Chrom Position Ref Alt GeneID|;
		push @fields => $f_iid;
		push @fields, sort keys %$fields;
		foreach my $fd (@fields) {
			unless (grep { $fd eq $_ } @$fnames) {
				die "Cannot find field $fd from input variant table";
			}
		}
		if (defined $qcfilter) {
			foreach my $tok (@$tokens) {
				if ($tok->[0] eq 'FIELD') {
					unless(grep { $tok->[1] eq $_ } @$fnames) {
						die "Cannot find Filter field $tok->[1] in variant table $vartab";
					}
				}
			}
		}
	}

	my %fouts;
	foreach my $sgroup (@analysgroup) {
		foreach my $varclass (map { $_->[0] } @analysclass) {
			my $outfile;
			if (@$sgroup == 1) {
				$outfile = "${varclass}_$sgroup->[0]";
			}
			elsif (@$sgroup == 2) {
				$outfile = "${varclass}_$sgroup->[0]vs$sgroup->[1]";
			}
			else {
				die "Incorrect number of sample group!"
			}
			push @outfiles, $outfile;
			$fouts{$outfile} = IO::File->new("$rootdir/wrk/varlist_$outfile", "w");
		}
	}

	my %known; # keep track of observed variants
	foreach my $vartab (@vartabs) {
		print STDERR "Parsing varinat table $vartab\n";
		my ($it, $fnames) = iter_file($vartab, { fsep => qr/\t/ });
		while(my $dat = $it->()) {
			my $iid = $dat->{$f_iid};
			if (%sampincl) {
				next unless defined $sampincl{$iid};
			}
			next if defined $samprm{$iid};
			# All sample in the variant table should be defined in sample table!
			unless(defined $sampgroup{$iid}) {
				warn "Cannot find sample group for $iid in $vartab";
				next;
			}
			# Skip samples not included in any analysis group
			if (none { defined $sampgroup{$iid}{$_} } map { @$_ } @analysgroup) {
				next;
			}
			# Skip variants in the exclusion list or failed QC filter
			my $varid = join(":", @{$dat}{qw|Chrom Position Ref Alt|});
			if (defined $qcfilter) {
				next unless $qcfilter->($dat);
			}
			if (%varexcl) {
				next if defined $varexcl{$iid,$varid} || defined $varexcl{$varid};
			}

			# Skip duplicated sample-variant combination
			if (defined $known{$iid,$varid}) {
				warn "Duplicated variant found in the variant table $vartab: $iid,$varid";
				next;
			}
			$known{$iid,$varid} = 1;

			# Determine sequence context
			my $context;
			unless ($dat->{Ref} =~ /^[ACGT]$/ && $dat->{Alt} =~ /^[ACGT]$/) {
				$context = '*';
			}
			else {
				if (defined $seq) {
					$context = $seq->get_slice($dat->{Chrom}, $dat->{Position}-1,$dat->{Position}+1);
				}
				else {
					die "Cannot find sequence context!" unless defined $dat->{Context};
					$context = $dat->{Context}; 
				}
				unless ($context =~ /^[ACGT]+\>[ACGT]+$/) {
					$context = '*';
				}
			}

			# Go through each gene-variant combination
			my @data = expand_dat($dat, { sep => ';', optional => ["GeneID", keys %$fields] });
			foreach my $data (@data) {
				# Skip variants that need removal
				next if defined $varrm{$iid,$varid}{$data->{GeneID}};
				# Deterimine all possibe variant classes
				my %varclass;
				for(my $ii = 0; $ii < @$varcls; $ii ++) {
					if ($filters->[$ii]->($data)) {
						$varclass{$varcls->[$ii]} = 1;
					}
				}
				next unless %varclass;
				# Skip variant not associated with any analysis class
				if (none { defined $varclass{$_} } map { keys %{$_->[1]} } @analysclass) {
					next;
				}
				# Now go-through each sample group to write out variants
				foreach my $sgroup (@analysgroup) {
					my @sampgrp = grep { defined $sampgroup{$iid}{$_} } @$sgroup;
					next unless @sampgrp;
					if (@sampgrp > 1) {
						die "One individual cannot belong to more than one group for comparison: $iid";
					}
					if ($twinsibs{$iid}) {
						# see if variant carried by a twin/sib in the same group
						my @samegrp = grep { defined $sampgroup{$iid} && defined $sampgroup{$iid}{$sampgrp[0]} } @{$twinsibs{$iid}};
						if (any { defined $known{$_,$varid} } @samegrp) {
							next;
						}
					}
					foreach my $vclass (@analysclass) {
						my @varcls = grep { defined $varclass{$_} } keys %{$vclass->[1]};
						next unless @varcls;
						if (@varcls > 1) {
							die "Cannot belong to multiple primitive variant class: $varid";
						}
						my $outfile = @$sgroup == 1 ? "$vclass->[0]_$sgroup->[0]" : "$vclass->[0]_$sgroup->[0]vs$sgroup->[1]";
						# Format: individual1	geneA	mutation_class	mutation_weight	comparative
						#		  individual2	geneD	mutation_class	mutation_weight	comparative
						$fouts{$outfile}->print(join("\t", $iid, $data->{GeneID}, $context.":".$clsalias{$varcls[0]}, 
												$vclass->[1]{$varcls[0]}, $sampgrp[0] eq $sgroup->[0] ? 1 : 0 ), "\n");
					}
				}
			}
		}
	}
}

# 
# Parse gene sets
#
# All gene sets to be tested will be written to a single gene set file
# wrk/genesets
{
	# Output format: geneA	set1	weight_geneA_set1
	# 		  		 geneB	set1	weight_geneB_set1
	my ($gs, $gsmember) = read_geneset($conf{Gene}{Set}, $conf{Gene}{Set_Fields});
	open my $fgs, ">$rootdir/wrk/genesets" or die "Cannot write to genesets";
	while(my ($set, $genes) = each %$gs) {
		foreach my $gene (uniq sort @$genes) {
			print $fgs join("\t", $gene, $set, $gsmember->{$gene}{$set}), "\n";
		}
	}
}

# 
# Parse gene size matrix 
# 
# Also parse additional background gene sets
# Each background set will be one file
# wrk/background_All, wrk/background_Label ...
my @bgsets = ("All");
my %generm;
{
	open my $fin, $conf{GeneSize}{Matrix} or die "Cannot open $conf{GeneSize}{Matrix}";
	my $header = <$fin>;
	my @allgenes = split(/\s+/, $header); shift @allgenes; shift @allgenes;
	if (defined $conf{Gene}{Exclude}) {
		%generm = map { (split)[0] => 1 } slurp $conf{Gene}{Exclude};
	}
	open my $fout, ">$rootdir/wrk/background_All" or die "Cannot write to background_All";
	foreach my $gene (@allgenes) {
		next if defined $generm{$gene};
		print $fout $gene, "\n";
	} 

	my $bg = read_geneset($conf{Gene}{BackGround}, $conf{Gene}{BackGround_Fields});
	while(my ($label, $genes) = each %$bg) {
		if ($label eq 'All') {
			die "Background set name All is reserved!";
		}
		open my $fout, ">$rootdir/wrk/background_$label" or die "Cannot write to background_$label";
		foreach my $gene (uniq sort @$genes) {
			next if defined $generm{$gene};
			print $fout $gene, "\n";
		}
		push @bgsets, $label;
	}
}

# write to analysis files
my $ct = 1;
foreach my $bgset (@bgsets)  {
	foreach my $sgroup (@analysgroup) {
		foreach my $varclass (map { $_->[0] } @analysclass) {	
			open my $fout, ">$rootdir/par/analysis.$ct" or die "Cannot write to analysis.$ct";
			print $fout join("\t", $varclass, $bgset, @$sgroup), "\n";
			$ct ++;
		}
	}
}

# Gene name alias for reformating output
# par/alias
if (defined $conf{Gene}{Alias}) {
	my ($it, $fnames, $keyfields) = parse_tabfile($conf{Gene}{Alias}, $conf{Gene}{Alias_Fields}, 2, 2);
	open my $fout, ">$rootdir/par/alias" or die "Cannot write to alias";
	while(my $dat = $it->()) {
		print $fout join("\t", @{$dat}{@$keyfields}), "\n";
	}
}


#################################
##  Workflow initialization &  ##
##  Working directory setup    ##
#################################

$conf{PATH}{MODULE} = shell_quote("$Bin/module");
$conf{PATH}{GENESIZE} = $conf{GeneSize}{Matrix};

# Note when results of calling all_combs ([A B C], [1 2 3]): A1 B1 C1 A2 B2 C2 A3 B3 C3
# Here all_combs(outfiles, bgset) matches the order that analysis._INDEX_ was generated.
$wkf->add(dnenrich(), { name => 'DNEnrich', nslots => scalar(@outfiles) * scalar(@bgsets),
						expect => [ map { "wrk/dnenrich_$_->[0]_$_->[1]" } all_combs(\@outfiles, \@bgsets) ]  } )
	->add(collect_res(), { name => "CollectRes", depend => 'DNEnrich',
							expect => ["out/Enrich.txt", "out/Contra.txt"] });

################################
## Kickstart workflow engine  ##
################################

$wkf->inst(\%conf);
$wkf->run({ conf => $conf{$wkf->{engine}}, dryrun => $opt->get_dryrun });


############################
## Workflow components    ##
############################

sub dnenrich {
	my $script = <<'EOF';

read VARCLS BGLABEL GRP1 GRP2 < _PARDIR_/analysis._INDEX_

if [[ -z $GRP2 ]]; then
	OUTGRP=$GRP1
else
	OUTGRP=${GRP1}vs${GRP2}
fi

dnenrich . _PARAM.NPERM_ /dev/null _PATH.GENESIZE_ _WRKDIR_/genesets _WRKDIR_/varlist_${VARCLS}_${OUTGRP} \
	_WRKDIR_/background_$BGLABEL > _WRKDIR_/dnenrich_${VARCLS}_${OUTGRP}_${BGLABEL} 

EOF
}

# Collect dnenrich results
sub collect_res {
	my $script = <<'EOF';

perl _PATH.MODULE_/collect_dnenrich.pl _PARDIR_ _WRKDIR_ _OUTDIR_

EOF
}
